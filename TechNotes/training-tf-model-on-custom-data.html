<!DOCTYPE html>
<html>
    <head>
        <!-- Global site tag (gtag.js) - Google Analytics -->
        <script async src="https://www.googletagmanager.com/gtag/js?id=UA-151725252-1"></script>
        <!-- Script for tracking using google analytics -->
        <script>
            window.dataLayer = window.dataLayer || [];
            function gtag(){dataLayer.push(arguments);}
            gtag('js', new Date());
        
            gtag('config', 'UA-151725252-1');
        </script>
        <title>Bitz'nPieces</title>
        <!-- <link rel="stylesheet" type="text/css" href="PATHTOCSSHERE">.-->
        <link rel="stylesheet" type="text/css" href="../styles/Post_Style.css">
        <link rel="stylesheet" type="text/css" href="../styles/google-code-prettify/prettify.css">
        <link rel="alternate" type="application/rss+xml" title="Subscribe to new bitz" href="http://your-site.com/your-feed.rss" />
    </head>
    <body>
        <section>
                <h1> Bitz'nPieces</h1>
        </section>

        <div class="topnav">
                <a href=../index.html href="#home">Home</a>
                <a href=../CommingSoon.html>Archive</a>
                <a href=../technotes.html>Tech Notes</a>
                <a href=../aboutme.html>About</a>
        </div>

        <section class="PostText">
            <h2> Training An Object Detector On Custom Data.</h2>
            <p> In this article I am going to describe how you can train one of the pre-trained models available on <a href="https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/detection_model_zoo.md">
                tensorflow model zoo</a> to detect and identify items of your choice. There are some pre-requisites that you need to have like some software and library installations.
                These have been described in detail in an earlier tutorial about performing object detections using a pre-trained model and TensorFlow Object-Detection-API. The link to
                that article is <a href="../TechNotes/tensor-flow-object-detection-api.html">
                here</a>.
            </p>
            <h3>LabelImg Installation:</h3>
            <p>
            One thing that I did not cover in the earlier article was the tool LabelImg. This is a very handy piece of software which is used for annotating images i.e. 
            we can use it to draw bounding boxes around the objects that we need to be detected by our detector in this software and it generates an xml file with the 
            co-ordinates of the box corresponding to each image in the dataset. The tool is opensource and is available on this <a href="https://github.com/tzutalin/labelImg">github repo</a>
            </p>
            <p>To install the tool simply run the following command in terminal</p>
            <pre><code><p class=codeHighlighting>pip install labelImg
<a style="color:rgb(102, 100, 100);"># To run the tool, execute the following command in terminal:</a>
labelImg</p></code></pre>
            </p>

            <p>So lets start preping the workspace and getting this thing done.</p>

            <h3>.</h3>
            <p> <b>STEP-1: Setting up the workspace:</b> From the last article we should already have a partial workspace setup, with a parent folder "ObjectDetection"
                and a sub-folder named "tensorflow" containing the clone of the tf-models in the folder named "models". The following image shows the final directory structure
                that I am going to be using throughout this article.
<img class="imgHighlighting" src="../TechNotes/assets/tf-workspace-structure.png">

            </p>
            <p><b>STEP-2: Preparing the dataset: </b></p>
            <p><b>....2.1: Annotating the images:</b>At this point I assume that you already have your data-set images in a directory
                all ready to be annotated. So go on ahead and fire up labelImg</p>
            <pre><code><p class=codeHighlighting>(tfenv) (base) ahmad@bitznpieces:~/ObjectDetection$ labelImg</p></code></pre>
            <p>Click on <b>Open Dir</b> and point to the directory containing the your dataset. You should see the <b>File List</b>
            view gets populated with the links to the images in the selected directory. Now all you have to do is iterate through all
            of the images and draw bounding boxes around the objects that you want to be detected on all of these images.
            Some handy key-board shortcuts for labelImg are:
            </p>
            <p><b>w:</b> Draw bounding box.</p>
            <p><b>a:</b> Iterate one step back in the files-list.</p>
            <p><b>d:</b> Iterate one step forward in the files-list.</p>
            <p>This process can take up a lot of time, so I will leave you guys to it. See ya'all on the other side...</p>

            <p><b>....2.2: Partitioning Into Test & Train Sets: </b> Commonly a data set is not used in its entirety for just
                training, rather it is divided (90/10 commonly but you can use any ratio you want theoretically) into training and 
                testing datasets. Now there are several open-source scripts and tools available for doing this partitioning, but 
                I just do it manually. I will try to write a script my-self later and post it here when I get the time.
            </p>
            <p> Create two directories named <b>test</b> and <b>train</b> inside <i>/workspace/dataset/</i> directory, and partition
                your data-set e.g. if you have 1000 images take a 100 and put them in the test directory and the rest 900 in the train directory
                along with their .xml files containing the metadata for annotations.
            </p>
            <p><b>STEP-3: Label-Map: </b> Im gonna go do some chores now, will get back to this soon, stay tuned for more
                thrilling steps...To be continued...</p>
            <div class=endOfSection><p> * ------ * ------ * ------ *</p></div>
        </section>
        <br>
        <footer class="MainFooter"> 
            <p>Disclaimer: This blog entry was written in #socialdistancing mode day-unknown.</p>
        </footer>

    <script src="../styles/google-code-prettify/prettify.js"></script>
    <script>
        window.onload = (function(){ prettyPrint(); });
    </script>
    </body>

</html>